{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 2 Practice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this practice module, we will walk through the process of creating, storing [and accessing], and using OAuth tokens for interacting with Twitter's APIs.\n",
    "\n",
    "In the following section, \"Obtaining a Twitter OAuth token,\" step by step instructions are provided, describing how to create a Twitter application and, subsequently, how to use the accompanied API keys to then create a re-usable Twitter token.\n",
    "\n",
    "While this process was actually done and can be repeated in an interactive session, it's a little bit tricker to do so in a JupyterHub environment. This is because in order to authorize access to an app on behalf of your Twitter account, it's easier to ask a user in an interactive session---meaning, a pop-up screen asking you to [if necessary] sign into Twitter and grant access to an application. Unfortunately, JupyterHub's integration with R doesn't allow for this kind of interactivity. Plus, since these notebooks are being executed on a DSA server, we can't assume that signing into your Twitter account is a simple and reasonable task. For these reasons, while it is possible to follow the steps below to create your own Twitter token locally (on your own machine in a local R session), you are only expected to use the token provided to you later on. The only real downside in functionality is that you'd need to create your own token to have write access, i.e., posting tweets or following users from an R console."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter oauth token\n",
    "\n",
    "1. Navigate to https://apps.twitter.com. Make sure you are signed into your Twitter account.\n",
    "2. Select \"create new app.\"\n",
    "3. Enter information to create your own app (using any working URL and entering the same callback URL listed below).\n",
    "<!-- ![](ss/create_app.png) -->\n",
    "<img style=\"max-width:700px\" src=\"ss/create_app.png\" />\n",
    "\n",
    "4. Click agree and submit application.\n",
    "<!-- ![](ss/submit_app.png) -->\n",
    "<img style=\"max-width:700px\" src=\"ss/submit_app.png\" />\n",
    "\n",
    "5. If it's successful, it will look like this:\n",
    "<!-- ![](ss/success.png) -->\n",
    "<img style=\"max-width:700px\"  src=\"ss/success.png\" />\n",
    "\n",
    "6. Go to \"Keys and Access Tokens\" and copy/paste the values for Consumer Key (API Key) and Consumer Secret (API Secret)\n",
    "<img style=\"max-width:700px\" src=\"ss/keys.png\" />\n",
    "<!-- ![](ss/keys.png) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    ".rendered_html img, .rendered_html svg, img { \n",
    "  max-width: 50% !important;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter the values for the app name, key, and secret. Create an app object and then create a token (note: this won't work in jupyter hub; it must be done in an interactive session). In the next chunk, we'll just read the token in, instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## values\n",
    "#app_name <- \"data_sci_8001\"\n",
    "#key <- \"nImVTaVIeo6tYlKnwYgxPRquQ\"\n",
    "#secret <- \"XqYrvQWimS8bD4ePrgq4M2UGN4p7FMUybJalnPfglwvSXTVEeW\"\n",
    "\n",
    "## create app\n",
    "#app <- httr::oauth_app(app_name, key, secret)\n",
    "\n",
    "## create token (must be interactive session)\n",
    "#token <- httr::oauth1.0_token(\n",
    "#    httr::oauth_endpoints(\"twitter\"),\n",
    "#    app, cache = FALSE\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing and calling tokens\n",
    "\n",
    "As was explained at the beginning of this notebook, we cannot create a new token following the steps outlined above in the current Jupyter notebook. So, instead, I would like you to read-in the token that was actually created using the information captured in the screen shots above.\n",
    "\n",
    "The token is saved in this module 2 practice (`modules/module2/practice/`) directory, so it can be read into an R session by simply specifying the file name using the `readRDS()` (read R data) function. The code below reads the file and stores it as `token`. By wrapping the parentheses around the call, it also prints the token object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Token>\n",
       "<oauth_endpoint>\n",
       " request:   https://api.twitter.com/oauth/request_token\n",
       " authorize: https://api.twitter.com/oauth/authenticate\n",
       " access:    https://api.twitter.com/oauth/access_token\n",
       "<oauth_app> data_sci_8001\n",
       "  key:    nImVTaVIeo6tYlKnwYgxPRquQ\n",
       "  secret: <hidden>\n",
       "<credentials> oauth_token, oauth_token_secret, user_id, screen_name, x_auth_expires\n",
       "---"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## read and print token\n",
    "(token <- readRDS(\"data_sci_8001_token.rds\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This token will be used in all of the calls made to Twitter's APIs. So, to make using the token easier, we will first save the token path as an environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## expand full path to token\n",
    "path_to_token <- normalizePath(\"data_sci_8001_token.rds\")\n",
    "\n",
    "## create env variable TWITTER_PAT (with path to saved token)\n",
    "envvar <- paste0(\"TWITTER_PAT=\", path_to_token)\n",
    "\n",
    "## save as .Renviron file (or append if the file already exists)\n",
    "cat(envvar, file = \"~/.Renviron\", fill = TRUE, append = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'/dsa/home/mdsmr6/DSA-STREAMING_mdsmr6/modules/module2/practice/data_sci_8001_token.rds'"
      ],
      "text/latex": [
       "'/dsa/home/mdsmr6/DSA-STREAMING\\_mdsmr6/modules/module2/practice/data\\_sci\\_8001\\_token.rds'"
      ],
      "text/markdown": [
       "'/dsa/home/mdsmr6/DSA-STREAMING_mdsmr6/modules/module2/practice/data_sci_8001_token.rds'"
      ],
      "text/plain": [
       "[1] \"/dsa/home/mdsmr6/DSA-STREAMING_mdsmr6/modules/module2/practice/data_sci_8001_token.rds\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_to_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'TWITTER_PAT=/dsa/home/mdsmr6/DSA-STREAMING_mdsmr6/modules/module2/practice/data_sci_8001_token.rds'"
      ],
      "text/latex": [
       "'TWITTER\\_PAT=/dsa/home/mdsmr6/DSA-STREAMING\\_mdsmr6/modules/module2/practice/data\\_sci\\_8001\\_token.rds'"
      ],
      "text/markdown": [
       "'TWITTER_PAT=/dsa/home/mdsmr6/DSA-STREAMING_mdsmr6/modules/module2/practice/data_sci_8001_token.rds'"
      ],
      "text/plain": [
       "[1] \"TWITTER_PAT=/dsa/home/mdsmr6/DSA-STREAMING_mdsmr6/modules/module2/practice/data_sci_8001_token.rds\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "envvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally the .Renviron file is processed on startup. However, to make sure the current R session registers the environment variable without having to restart the entire session, we can use the `readRenviron()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## refresh .Renviron variables\n",
    "readRenviron(\"~/.Renviron\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can assume the path to our Twitter token is stored as an environment variable, we can easily write a function that locates and reads-in the token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Token>\n",
       "<oauth_endpoint>\n",
       " request:   https://api.twitter.com/oauth/request_token\n",
       " authorize: https://api.twitter.com/oauth/authenticate\n",
       " access:    https://api.twitter.com/oauth/access_token\n",
       "<oauth_app> data_sci_8001\n",
       "  key:    nImVTaVIeo6tYlKnwYgxPRquQ\n",
       "  secret: <hidden>\n",
       "<credentials> oauth_token, oauth_token_secret, user_id, screen_name, x_auth_expires\n",
       "---"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## function to load twitter token\n",
    "read_twittertoken <- function() {\n",
    "    readRDS(Sys.getenv(\"TWITTER_PAT\"))\n",
    "}\n",
    "\n",
    "## test out function\n",
    "read_twittertoken()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we keep running the above code, we'll keep adding new lines to our environment file. In addition to creating a mess in your .Renviron file, each successive line will override the previous value. In other words, you're doomed to make a mistake; and when you do, it will override the times that worked. \n",
    "\n",
    "So, to fix this problem, let's take the code we used to create and save the token as an environment variable and turn it into a single, useful function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_renv_token <- function(path_to_token, override = FALSE) {\n",
    "    ## check path\n",
    "    stopifnot(\n",
    "        is.character(path_to_token),\n",
    "        file.exists(path_to_token)\n",
    "    )\n",
    "    ## expand to full path\n",
    "    path_to_token <- normalizePath(path_to_token)\n",
    "\n",
    "    ## store path to .Renviron\n",
    "    renv <- normalizePath(\"~/.Renviron\")\n",
    "    \n",
    "    ## if override = false and there's already a TWITTER_PAT, stop\n",
    "    ## else override and there's already a TWITTER_PAT, then drop TWITTER_PAT and\n",
    "    ## save new .Renviron\n",
    "    if (!override && !identical(Sys.getenv(\"TWITTER_PAT\"), \"\")) {\n",
    "        stop(\"There's already a TWITTER_PAT. Use `override = TRUE` to replace.\",\n",
    "            call. = FALSE)\n",
    "    } else if (!identical(Sys.getenv(\"TWITTER_PAT\"), \"\") && \n",
    "               file.exists(renv)) {\n",
    "        con <- file(renv)\n",
    "        x <- readLines(con, warn = FALSE)\n",
    "        close(con)\n",
    "        x <- grep(\"^TWITTER_PAT\", x, invert = TRUE, value = TRUE)\n",
    "        writeLines(x, renv)\n",
    "    }\n",
    "    \n",
    "    ## create env variable TWITTER_PAT (with path to saved token)\n",
    "    envvar <- paste0(\"TWITTER_PAT=\", path_to_token)\n",
    "    \n",
    "    ## save as .Renviron file (or append if the file already exists)\n",
    "    cat(envvar, file = renv, fill = TRUE, append = TRUE)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test out the function. Because we saved the token as an environment variable earlier, we should get our error message about already having a TWITTER_PAT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error: There's already a TWITTER_PAT. Use `override = TRUE` to replace.\n",
     "output_type": "error",
     "traceback": [
      "Error: There's already a TWITTER_PAT. Use `override = TRUE` to replace.\nTraceback:\n",
      "1. set_renv_token(\"data_sci_8001_token.rds\")",
      "2. stop(\"There's already a TWITTER_PAT. Use `override = TRUE` to replace.\", \n .     call. = FALSE)   # at line 17-18 of file <text>"
     ]
    }
   ],
   "source": [
    "set_renv_token(\"data_sci_8001_token.rds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To force the update the token environment variable, set `override = TRUE` and it should work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_renv_token(\"data_sci_8001_token.rds\", override = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Token>\n",
       "<oauth_endpoint>\n",
       " request:   https://api.twitter.com/oauth/request_token\n",
       " authorize: https://api.twitter.com/oauth/authenticate\n",
       " access:    https://api.twitter.com/oauth/access_token\n",
       "<oauth_app> data_sci_8001\n",
       "  key:    nImVTaVIeo6tYlKnwYgxPRquQ\n",
       "  secret: <hidden>\n",
       "<credentials> oauth_token, oauth_token_secret, user_id, screen_name, x_auth_expires\n",
       "---"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "read_twittertoken()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Search API\n",
    "\n",
    "Now let's create a function that allows us to query [Twitter's standard search API](https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets). In the code below, I've included all the documented parameters (see note for explanation of the additional `tweet_mode` parameter), setting the optional parameters to `NULL` and making some judgment calls about other ones (e.g., `result_type` and `include_entitities`).\n",
    "\n",
    "*Note*: in order to return the full (non-truncated) text of a tweet, a [recent change by Twitter](https://developer.twitter.com/en/docs/tweets/tweet-updates) requires all requests for data on Twitter statuses include the paramater `tweet_mode=extended`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## search query function\n",
    "search_twitter <- function(q, geocode = NULL, \n",
    "                           lang = NULL, \n",
    "                           locale = NULL, \n",
    "                           result_type = \"recent\", \n",
    "                           count = 100, \n",
    "                           until = NULL, \n",
    "                           max_id = NULL, \n",
    "                           include_entities = TRUE) {\n",
    "    ## URL scheme and hostname\n",
    "    base_url <- \"https://api.twitter.com\"\n",
    "    ## include the API version number as part of the path\n",
    "    path <- \"1.1/search/tweets.json\"\n",
    "    ## check result type\n",
    "    if (!result_type %in% c(\"recent\", \"popular\", \"mixed\")) {\n",
    "        stop(\"result_type must be one of recent, popular, or mixed\", \n",
    "            call. = FALSE)\n",
    "    }\n",
    "    ## build query parameters\n",
    "    params <- list(\n",
    "        q = q,\n",
    "        geocode = geocode,\n",
    "        lang = lang,\n",
    "        locale = locale,\n",
    "        result_type = result_type,\n",
    "        count = count,\n",
    "        until = until,\n",
    "        max_id = max_id,\n",
    "        include_entitities = include_entities,\n",
    "        tweet_mode = \"extended\"\n",
    "    )\n",
    "    ## send GET request\n",
    "    httr::GET(base_url, path = path, query = params, \n",
    "              httr::config(token = read_twittertoken()))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the `search_twitter()` function to search for all tweets mentioning \"rstats\". As noted in Twitter's documentation, searches will automatically include hashtag matches. Not including the pound sign `#` will thus return not only hashtag uses of rstats, e.g., \"I love #rstats\", but also other mentions of it as well, e.g., \"I love rstats.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## execute search for all tweets mentioning \"rstats\" (this will include hashtags)/\n",
    "rstats <- search_twitter(\"rstats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the response object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response [https://api.twitter.com/1.1/search/tweets.json?q=rstats&result_type=recent&count=100&include_entitities=TRUE&tweet_mode=extended]\n",
       "  Date: 2018-02-07 05:25\n",
       "  Status: 200\n",
       "  Content-Type: application/json;charset=utf-8\n",
       "  Size: 659 kB\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## view the response object\n",
    "rstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## parse as text (convert response object to json)\n",
    "js <- httr::content(rstats, as = \"text\", encoding = \"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## convert json character vector to R list\n",
    "d <- jsonlite::fromJSON(js)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the structure of the returned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 2\n",
      " $ statuses       :'data.frame':\t100 obs. of  31 variables:\n",
      " $ search_metadata:List of 9\n"
     ]
    }
   ],
   "source": [
    "str(d, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like all the good stuff is in \"statuses\", so let's inspect two levels down in `d$statuses`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t100 obs. of  31 variables:\n",
      " $ created_at               : chr  \"Wed Feb 07 05:20:56 +0000 2018\" \"Wed Feb 07 05:20:25 +0000 2018\" \"Wed Feb 07 05:20:04 +0000 2018\" \"Wed Feb 07 05:19:02 +0000 2018\" ...\n",
      " $ id                       : num  9.61e+17 9.61e+17 9.61e+17 9.61e+17 9.61e+17 ...\n",
      " $ id_str                   : chr  \"961107489562472449\" \"961107360428249089\" \"961107270502318086\" \"961107012254920705\" ...\n",
      " $ full_text                : chr  \"RT @KirkDBorne: Getting started with R programming basics : https://t.co/WWknbNeC8U #abdsc #Rstats #Statistics \"| __truncated__ \"RT @jakub_nowosad: Are you looking for the global dataset of gridded population and GDP? 1980-2010 estimations \"| __truncated__ \"RT @beeonaposy: Pandas documentation includes a handy guide on how to translate #dplyr verbs into pandas equiva\"| __truncated__ \"RT @ktaylor: One of my favorite R resources https://t.co/6HQxzsLCbU #rstats #phdchat\" ...\n",
      " $ truncated                : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n",
      " $ display_text_range       :List of 100\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 84\n",
      "  ..$ : int  0 154\n",
      "  ..$ : int  0 79\n",
      "  ..$ : int  42 102\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 139\n",
      "  ..$ : int  0 139\n",
      "  ..$ : int  0 61\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 139\n",
      "  ..$ : int  0 123\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 134\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 86\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 267\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 92\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 120\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 91\n",
      "  ..$ : int  0 91\n",
      "  ..$ : int  0 136\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 146\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 284\n",
      "  ..$ : int  0 91\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 144\n",
      "  ..$ : int  0 158\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 136\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 92\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 93\n",
      "  ..$ : int  0 144\n",
      "  ..$ : int  0 73\n",
      "  ..$ : int  0 134\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 93\n",
      "  ..$ : int  0 100\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 137\n",
      "  ..$ : int  0 144\n",
      "  ..$ : int  0 134\n",
      "  ..$ : int  0 118\n",
      "  ..$ : int  0 274\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 144\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 82\n",
      "  ..$ : int  0 144\n",
      "  ..$ : int  0 91\n",
      "  ..$ : int  0 144\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 134\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 112\n",
      "  ..$ : int  0 139\n",
      "  ..$ : int  0 92\n",
      "  .. [list output truncated]\n",
      " $ entities                 :'data.frame':\t100 obs. of  5 variables:\n",
      "  ..$ hashtags     :List of 100\n",
      "  ..$ symbols      :List of 100\n",
      "  ..$ user_mentions:List of 100\n",
      "  ..$ urls         :List of 100\n",
      "  ..$ media        :List of 100\n",
      " $ metadata                 :'data.frame':\t100 obs. of  2 variables:\n",
      "  ..$ iso_language_code: chr  \"en\" \"en\" \"en\" \"en\" ...\n",
      "  ..$ result_type      : chr  \"recent\" \"recent\" \"recent\" \"recent\" ...\n",
      " $ source                   : chr  \"<a href=\\\"http://twitter.com/download/iphone\\\" rel=\\\"nofollow\\\">Twitter for iPhone</a>\" \"<a href=\\\"http://twitter.com\\\" rel=\\\"nofollow\\\">Twitter Web Client</a>\" \"<a href=\\\"http://twitter.com/download/iphone\\\" rel=\\\"nofollow\\\">Twitter for iPhone</a>\" \"<a href=\\\"http://twitter.com/download/android\\\" rel=\\\"nofollow\\\">Twitter for Android</a>\" ...\n",
      " $ in_reply_to_status_id    : num  NA NA NA NA NA ...\n",
      " $ in_reply_to_status_id_str: chr  NA NA NA NA ...\n",
      " $ in_reply_to_user_id      : int  NA NA NA NA NA NA 941640842 NA NA NA ...\n",
      " $ in_reply_to_user_id_str  : chr  NA NA NA NA ...\n",
      " $ in_reply_to_screen_name  : chr  NA NA NA NA ...\n",
      " $ user                     :'data.frame':\t100 obs. of  42 variables:\n",
      "  ..$ id                                : num  1.68e+07 7.12e+08 4.48e+07 6.20e+07 4.92e+07 ...\n",
      "  ..$ id_str                            : chr  \"16842025\" \"712365739\" \"44782628\" \"62034993\" ...\n",
      "  ..$ name                              : chr  \"Dash Desai\" \"Parmutia Makui<U+2122>\" \"Chaim Kesler\" \"Lil_Jean\" ...\n",
      "  ..$ screen_name                       : chr  \"iamontheinet\" \"ParmutiaMakui\" \"Chaim_Kesler\" \"BabyJeanGrey\" ...\n",
      "  ..$ location                          : chr  \"San Jose, CA\" \"Nairobi, Kenya.\" \"New York, NY\" \"Gainesville, FL\" ...\n",
      "  ..$ description                       : chr  \"Tech Evangelist | #BigData | #CloudComputing | #DataScience @GA_SF | #Code | #Art | #Photography @natureunraveled | #Skiing\" \"|| Unique just like you || Seeking understanding ||\" \"#Data & #Technology for Democracy and Civil Liberties: Tweets and views are my own\" \"Social Craze of The Messy Me :P\" ...\n",
      "  ..$ url                               : chr  \"https://t.co/aFZJ6P6avG\" NA NA \"https://t.co/WKePNXP07e\" ...\n",
      "  ..$ entities                          :'data.frame':\t100 obs. of  2 variables:\n",
      "  ..$ protected                         : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n",
      "  ..$ followers_count                   : int  740 259 112 203 110 45 729 683 641 1472 ...\n",
      "  ..$ friends_count                     : int  708 306 523 896 165 90 520 475 1018 2114 ...\n",
      "  ..$ listed_count                      : int  766 104 7 2 21 4 25 45 78 57 ...\n",
      "  ..$ created_at                        : chr  \"Sat Oct 18 18:53:24 +0000 2008\" \"Mon Jul 23 12:43:37 +0000 2012\" \"Fri Jun 05 01:08:35 +0000 2009\" \"Sat Aug 01 13:40:29 +0000 2009\" ...\n",
      "  ..$ favourites_count                  : int  652 1297 270 129 436 5 724 678 1 11436 ...\n",
      "  ..$ utc_offset                        : int  -28800 10800 -28800 28800 -18000 NA -18000 3600 3600 -25200 ...\n",
      "  ..$ time_zone                         : chr  \"Pacific Time (US & Canada)\" \"Nairobi\" \"Pacific Time (US & Canada)\" \"Kuala Lumpur\" ...\n",
      "  ..$ geo_enabled                       : logi  TRUE TRUE TRUE TRUE FALSE TRUE ...\n",
      "  ..$ verified                          : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n",
      "  ..$ statuses_count                    : int  11312 6528 321 13274 576 242 2459 6675 27434 11682 ...\n",
      "  ..$ lang                              : chr  \"en\" \"en\" \"en\" \"en\" ...\n",
      "  ..$ contributors_enabled              : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n",
      "  ..$ is_translator                     : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n",
      "  ..$ is_translation_enabled            : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n",
      "  ..$ profile_background_color          : chr  \"C6E2EE\" \"8B542B\" \"C0DEED\" \"C0DEED\" ...\n",
      "  ..$ profile_background_image_url      : chr  \"http://abs.twimg.com/images/themes/theme2/bg.gif\" \"http://pbs.twimg.com/profile_background_images/624086828560203777/wgtof1KC.jpg\" \"http://pbs.twimg.com/profile_background_images/328132998/Picture_1.png\" \"http://pbs.twimg.com/profile_background_images/211192514/AZ-450x562.jpg\" ...\n",
      "  ..$ profile_background_image_url_https: chr  \"https://abs.twimg.com/images/themes/theme2/bg.gif\" \"https://pbs.twimg.com/profile_background_images/624086828560203777/wgtof1KC.jpg\" \"https://pbs.twimg.com/profile_background_images/328132998/Picture_1.png\" \"https://pbs.twimg.com/profile_background_images/211192514/AZ-450x562.jpg\" ...\n",
      "  ..$ profile_background_tile           : logi  FALSE TRUE TRUE TRUE FALSE FALSE ...\n",
      "  ..$ profile_image_url                 : chr  \"http://pbs.twimg.com/profile_images/763225259168325632/4QitBXwS_normal.jpg\" \"http://pbs.twimg.com/profile_images/378800000579863228/e575b07b2289af63e2015890413f5291_normal.jpeg\" \"http://pbs.twimg.com/profile_images/893593764765282304/jc9eFPuL_normal.jpg\" \"http://pbs.twimg.com/profile_images/3247470744/424099ac342f2be18745c67eda1c6c0d_normal.jpeg\" ...\n",
      "  ..$ profile_image_url_https           : chr  \"https://pbs.twimg.com/profile_images/763225259168325632/4QitBXwS_normal.jpg\" \"https://pbs.twimg.com/profile_images/378800000579863228/e575b07b2289af63e2015890413f5291_normal.jpeg\" \"https://pbs.twimg.com/profile_images/893593764765282304/jc9eFPuL_normal.jpg\" \"https://pbs.twimg.com/profile_images/3247470744/424099ac342f2be18745c67eda1c6c0d_normal.jpeg\" ...\n",
      "  ..$ profile_banner_url                : chr  \"https://pbs.twimg.com/profile_banners/16842025/1488078643\" \"https://pbs.twimg.com/profile_banners/712365739/1469714126\" \"https://pbs.twimg.com/profile_banners/44782628/1425355887\" \"https://pbs.twimg.com/profile_banners/62034993/1360748734\" ...\n",
      "  ..$ profile_link_color                : chr  \"181818\" \"981CEB\" \"0084B4\" \"0084B4\" ...\n",
      "  ..$ profile_sidebar_border_color      : chr  \"C6E2EE\" \"FFFFFF\" \"C0DEED\" \"C0DEED\" ...\n",
      "  ..$ profile_sidebar_fill_color        : chr  \"DAECF4\" \"EADEAA\" \"DDEEF6\" \"DDEEF6\" ...\n",
      "  ..$ profile_text_color                : chr  \"663B12\" \"333333\" \"333333\" \"333333\" ...\n",
      "  ..$ profile_use_background_image      : logi  FALSE TRUE FALSE TRUE FALSE TRUE ...\n",
      "  ..$ has_extended_profile              : logi  TRUE TRUE FALSE TRUE TRUE TRUE ...\n",
      "  ..$ default_profile                   : logi  FALSE FALSE FALSE FALSE FALSE TRUE ...\n",
      "  ..$ default_profile_image             : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n",
      "  ..$ following                         : logi  FALSE TRUE FALSE FALSE FALSE FALSE ...\n",
      "  ..$ follow_request_sent               : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n",
      "  ..$ notifications                     : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n",
      "  ..$ translator_type                   : chr  \"none\" \"none\" \"none\" \"none\" ...\n",
      " $ geo                      : logi  NA NA NA NA NA NA ...\n",
      " $ coordinates              : logi  NA NA NA NA NA NA ...\n",
      " $ place                    : logi  NA NA NA NA NA NA ...\n",
      " $ contributors             : logi  NA NA NA NA NA NA ...\n",
      " $ retweeted_status         :'data.frame':\t100 obs. of  30 variables:\n",
      "  ..$ created_at               : chr  \"Tue Feb 06 16:48:57 +0000 2018\" \"Tue Feb 06 17:08:24 +0000 2018\" \"Tue Feb 06 01:36:33 +0000 2018\" \"Wed Feb 07 02:49:26 +0000 2018\" ...\n",
      "  ..$ id                       : num  9.61e+17 9.61e+17 9.61e+17 9.61e+17 NA ...\n",
      "  ..$ id_str                   : chr  \"960918247817310208\" \"960923139327787009\" \"960688632498737152\" \"961069364370960384\" ...\n",
      "  ..$ full_text                : chr  \"Getting started with R programming basics : https://t.co/WWknbNeC8U #abdsc #Rstats #Statistics #DataScience #co\"| __truncated__ \"Are you looking for the global dataset of gridded population and GDP? 1980-2010 estimations and 2020-2100 scena\"| __truncated__ \"Pandas documentation includes a handy guide on how to translate #dplyr verbs into pandas equivalents. <U+0001F6\"| __truncated__ \"One of my favorite R resources https://t.co/6HQxzsLCbU #rstats #phdchat\" ...\n",
      "  ..$ truncated                : logi  FALSE FALSE FALSE FALSE NA FALSE ...\n",
      "  ..$ display_text_range       :List of 100\n",
      "  ..$ entities                 :'data.frame':\t100 obs. of  5 variables:\n",
      "  ..$ extended_entities        :'data.frame':\t100 obs. of  1 variable:\n",
      "  ..$ metadata                 :'data.frame':\t100 obs. of  2 variables:\n",
      "  ..$ source                   : chr  \"<a href=\\\"http://twitter.com\\\" rel=\\\"nofollow\\\">Twitter Web Client</a>\" \"<a href=\\\"http://twitter.com\\\" rel=\\\"nofollow\\\">Twitter Web Client</a>\" \"<a href=\\\"http://twitter.com\\\" rel=\\\"nofollow\\\">Twitter Web Client</a>\" \"<a href=\\\"http://twitter.com/download/android\\\" rel=\\\"nofollow\\\">Twitter for Android</a>\" ...\n",
      "  ..$ in_reply_to_status_id    : num  NA NA NA NA NA NA NA NA NA NA ...\n",
      "  ..$ in_reply_to_status_id_str: chr  NA NA NA NA ...\n",
      "  ..$ in_reply_to_user_id      : num  NA NA NA NA NA NA NA NA NA NA ...\n",
      "  ..$ in_reply_to_user_id_str  : chr  NA NA NA NA ...\n",
      "  ..$ in_reply_to_screen_name  : chr  NA NA NA NA ...\n",
      "  ..$ user                     :'data.frame':\t100 obs. of  42 variables:\n",
      "  ..$ geo                      : logi  NA NA NA NA NA NA ...\n",
      "  ..$ coordinates              : logi  NA NA NA NA NA NA ...\n",
      "  ..$ place                    : logi  NA NA NA NA NA NA ...\n",
      "  ..$ contributors             : logi  NA NA NA NA NA NA ...\n",
      "  ..$ is_quote_status          : logi  FALSE FALSE FALSE FALSE NA FALSE ...\n",
      "  ..$ retweet_count            : int  50 30 48 3 NA 8 NA 3 40 4 ...\n",
      "  ..$ favorite_count           : int  55 72 186 1 NA 31 NA 13 151 6 ...\n",
      "  ..$ favorited                : logi  FALSE FALSE FALSE FALSE NA FALSE ...\n",
      "  ..$ retweeted                : logi  FALSE FALSE FALSE FALSE NA FALSE ...\n",
      "  ..$ possibly_sensitive       : logi  FALSE FALSE FALSE FALSE NA FALSE ...\n",
      "  ..$ lang                     : chr  \"en\" \"en\" \"en\" \"en\" ...\n",
      "  ..$ quoted_status_id         : num  NA NA NA NA NA NA NA NA NA NA ...\n",
      "  ..$ quoted_status_id_str     : chr  NA NA NA NA ...\n",
      "  ..$ quoted_status            :'data.frame':\t100 obs. of  27 variables:\n",
      " $ is_quote_status          : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n",
      " $ retweet_count            : int  50 30 48 3 0 8 0 3 40 4 ...\n",
      " $ favorite_count           : int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ favorited                : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n",
      " $ retweeted                : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n",
      " $ possibly_sensitive       : logi  FALSE NA NA FALSE NA FALSE ...\n",
      " $ lang                     : chr  \"en\" \"en\" \"en\" \"en\" ...\n",
      " $ quoted_status_id         : num  NA NA NA NA NA NA NA NA NA NA ...\n",
      " $ quoted_status_id_str     : chr  NA NA NA NA ...\n",
      " $ quoted_status            :'data.frame':\t100 obs. of  27 variables:\n",
      "  ..$ created_at               : chr  NA NA NA NA ...\n",
      "  ..$ id                       : num  NA NA NA NA NA NA NA NA NA NA ...\n",
      "  ..$ id_str                   : chr  NA NA NA NA ...\n",
      "  ..$ full_text                : chr  NA NA NA NA ...\n",
      "  ..$ truncated                : logi  NA NA NA NA NA NA ...\n",
      "  ..$ display_text_range       :List of 100\n",
      "  ..$ entities                 :'data.frame':\t100 obs. of  5 variables:\n",
      "  ..$ extended_entities        :'data.frame':\t100 obs. of  1 variable:\n",
      "  ..$ metadata                 :'data.frame':\t100 obs. of  2 variables:\n",
      "  ..$ source                   : chr  NA NA NA NA ...\n",
      "  ..$ in_reply_to_status_id    : logi  NA NA NA NA NA NA ...\n",
      "  ..$ in_reply_to_status_id_str: logi  NA NA NA NA NA NA ...\n",
      "  ..$ in_reply_to_user_id      : logi  NA NA NA NA NA NA ...\n",
      "  ..$ in_reply_to_user_id_str  : logi  NA NA NA NA NA NA ...\n",
      "  ..$ in_reply_to_screen_name  : logi  NA NA NA NA NA NA ...\n",
      "  ..$ user                     :'data.frame':\t100 obs. of  42 variables:\n",
      "  ..$ geo                      : logi  NA NA NA NA NA NA ...\n",
      "  ..$ coordinates              : logi  NA NA NA NA NA NA ...\n",
      "  ..$ place                    :'data.frame':\t100 obs. of  10 variables:\n",
      "  ..$ contributors             : logi  NA NA NA NA NA NA ...\n",
      "  ..$ is_quote_status          : logi  NA NA NA NA NA NA ...\n",
      "  ..$ retweet_count            : int  NA NA NA NA NA NA NA NA NA NA ...\n",
      "  ..$ favorite_count           : int  NA NA NA NA NA NA NA NA NA NA ...\n",
      "  ..$ favorited                : logi  NA NA NA NA NA NA ...\n",
      "  ..$ retweeted                : logi  NA NA NA NA NA NA ...\n",
      "  ..$ possibly_sensitive       : logi  NA NA NA NA NA NA ...\n",
      "  ..$ lang                     : chr  NA NA NA NA ...\n",
      " $ extended_entities        :'data.frame':\t100 obs. of  1 variable:\n",
      "  ..$ media:List of 100\n"
     ]
    }
   ],
   "source": [
    "df <- d$statuses\n",
    "str(df, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The good news is that we have a lot of data. Not just the text of the tweets, but all sorts of other meta data. \n",
    "\n",
    "The bad news is that to conduct analysis on the data, we typically want to wrangle it into a data frame. For example, what if I wanted to see if the number of hashtags was predicted by the source of the tweet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 100\n",
      " $ :'data.frame':\t5 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:5] \"abdsc\" \"Rstats\" \"Statistics\" \"DataScience\" ...\n",
      "  ..$ indices:List of 5\n",
      " $ :'data.frame':\t0 obs. of  0 variables\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"dplyr\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"rstats\" \"phdchat\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t0 obs. of  0 variables\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t0 obs. of  0 variables\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t3 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:3] \"rstats\" \"tsibble\" \"tibbletime\"\n",
      "  ..$ indices:List of 3\n",
      " $ :'data.frame':\t0 obs. of  0 variables\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t5 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:5] \"BigData\" \"DataScience\" \"Analytics\" \"RStats\" ...\n",
      "  ..$ indices:List of 5\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"Rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t5 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:5] \"BigData\" \"DataScience\" \"Analytics\" \"RStats\" ...\n",
      "  ..$ indices:List of 5\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"Rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"Microsoft\" \"AI\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t5 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:5] \"BigData\" \"DataScience\" \"Analytics\" \"RStats\" ...\n",
      "  ..$ indices:List of 5\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t5 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:5] \"BigData\" \"DataScience\" \"Analytics\" \"RStats\" ...\n",
      "  ..$ indices:List of 5\n",
      " $ :'data.frame':\t5 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:5] \"BigData\" \"DataScience\" \"Analytics\" \"RStats\" ...\n",
      "  ..$ indices:List of 5\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"rstats\" \"ggplot2\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t5 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:5] \"BigData\" \"DataScience\" \"Analytics\" \"RStats\" ...\n",
      "  ..$ indices:List of 5\n",
      " $ :'data.frame':\t5 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:5] \"BigData\" \"DataScience\" \"Analytics\" \"RStats\" ...\n",
      "  ..$ indices:List of 5\n",
      " $ :'data.frame':\t5 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:5] \"BigData\" \"DataScience\" \"Analytics\" \"RStats\" ...\n",
      "  ..$ indices:List of 5\n",
      " $ :'data.frame':\t0 obs. of  0 variables\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"rstats\" \"dataScience\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"rstats\" \"dataScience\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t0 obs. of  0 variables\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"MachineLearning\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t5 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:5] \"Review\" \"DeepLearning\" \"NeuralNetworks\" \"DataScience\" ...\n",
      "  ..$ indices:List of 5\n",
      " $ :'data.frame':\t8 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:8] \"Review\" \"MachineLearning\" \"Python\" \"R\" ...\n",
      "  ..$ indices:List of 8\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"rstats\" \"ggplot2\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t5 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:5] \"BigData\" \"DataScientists\" \"AI\" \"ArtificialIntelligence\" ...\n",
      "  ..$ indices:List of 5\n",
      " $ :'data.frame':\t4 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:4] \"MachineLearning\" \"DeepLearning\" \"DataScientists\" \"AI\"\n",
      "  ..$ indices:List of 4\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"Rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t0 obs. of  0 variables\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"MachineLearning\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t0 obs. of  0 variables\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"Docker\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t3 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:3] \"rstats\" \"TimeToTeachThisOldDogNewTricks\" \"tidyverse\"\n",
      "  ..$ indices:List of 3\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"rstats\" \"ggplot\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"MachineLearning\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"MachineLearning\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"rstats\" \"ApacheSpark\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"rstats\" \"dataScience\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t0 obs. of  0 variables\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"Microsoft\" \"AI\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t5 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:5] \"abdsc\" \"Rstats\" \"Statistics\" \"DataScience\" ...\n",
      "  ..$ indices:List of 5\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"rstats\" \"datascience\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"Docker\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"Microsoft\" \"AI\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t5 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:5] \"abdsc\" \"Rstats\" \"Statistics\" \"DataScience\" ...\n",
      "  ..$ indices:List of 5\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"Rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t3 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:3] \"rstats\" \"tsibble\" \"tibbletime\"\n",
      "  ..$ indices:List of 3\n",
      " $ :'data.frame':\t0 obs. of  0 variables\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"Microsoft\" \"AI\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"Microsoft\" \"AI\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"rstats\" \"unitizer\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"rstats\" \"ggplot2\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"rstats\" \"datascience\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"Docker\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"Docker\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t6 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:6] \"BigData\" \"MachineLearning\" \"DataScience\" \"AI\" ...\n",
      "  ..$ indices:List of 6\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"RStats\" \"RStudio\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      "  [list output truncated]\n"
     ]
    }
   ],
   "source": [
    "str(df$entities$hashtags, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the hashtags object consist of 100 data frames, some of which have zero observations. So, we'll have to clean this up. I've done just that in the code below by first extracting the text of hashtags and then by replacing the NULL returns (data frames with zero observations and, consequently, no \"text\" variable) with a NA [of class character] value. The list of hashtags is then added to the `df` data frame, using the `I()` function to tell R that we know it's a recursive (more than one observation per) list. Finally, the number of hashtags are counted and added to the data frame as a variable named `hashtag_count`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## extract text of hashtags\n",
    "hashtags <- lapply(df$entities$hashtags, \"[[\", \"text\")\n",
    "## replace nulls with missing\n",
    "hashtags[lengths(hashtags) == 0L] <- NA_character_\n",
    "\n",
    "## add to df object\n",
    "df$hashtags <- I(hashtags)\n",
    "\n",
    "## calculate number of hashtags\n",
    "df$hashtag_count <- lengths(hashtags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how the `source` variable looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'&lt;a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\"&gt;Twitter for iPhone&lt;/a&gt;'</li>\n",
       "\t<li>'&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Twitter Web Client&lt;/a&gt;'</li>\n",
       "\t<li>'&lt;a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\"&gt;Twitter for iPhone&lt;/a&gt;'</li>\n",
       "\t<li>'&lt;a href=\"http://twitter.com/download/android\" rel=\"nofollow\"&gt;Twitter for Android&lt;/a&gt;'</li>\n",
       "\t<li>'&lt;a href=\"http://twitter.com/download/android\" rel=\"nofollow\"&gt;Twitter for Android&lt;/a&gt;'</li>\n",
       "\t<li>'&lt;a href=\"http://twitter.com/download/android\" rel=\"nofollow\"&gt;Twitter for Android&lt;/a&gt;'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>'\n",
       "\\item '<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>'\n",
       "\\item '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>'\n",
       "\\item '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>'\n",
       "\\item '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>'\n",
       "\\item '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. '&lt;a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\"&gt;Twitter for iPhone&lt;/a&gt;'\n",
       "2. '&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Twitter Web Client&lt;/a&gt;'\n",
       "3. '&lt;a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\"&gt;Twitter for iPhone&lt;/a&gt;'\n",
       "4. '&lt;a href=\"http://twitter.com/download/android\" rel=\"nofollow\"&gt;Twitter for Android&lt;/a&gt;'\n",
       "5. '&lt;a href=\"http://twitter.com/download/android\" rel=\"nofollow\"&gt;Twitter for Android&lt;/a&gt;'\n",
       "6. '&lt;a href=\"http://twitter.com/download/android\" rel=\"nofollow\"&gt;Twitter for Android&lt;/a&gt;'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"<a href=\\\"http://twitter.com/download/iphone\\\" rel=\\\"nofollow\\\">Twitter for iPhone</a>\"  \n",
       "[2] \"<a href=\\\"http://twitter.com\\\" rel=\\\"nofollow\\\">Twitter Web Client</a>\"                  \n",
       "[3] \"<a href=\\\"http://twitter.com/download/iphone\\\" rel=\\\"nofollow\\\">Twitter for iPhone</a>\"  \n",
       "[4] \"<a href=\\\"http://twitter.com/download/android\\\" rel=\\\"nofollow\\\">Twitter for Android</a>\"\n",
       "[5] \"<a href=\\\"http://twitter.com/download/android\\\" rel=\\\"nofollow\\\">Twitter for Android</a>\"\n",
       "[6] \"<a href=\\\"http://twitter.com/download/android\\\" rel=\\\"nofollow\\\">Twitter for Android</a>\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(df$source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source includes html code. Fortunately, we can extract the key text with relative ease using a regular expression like the one below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df$source <- stringr::str_extract(df$source, \"(?<=\\\\>)[^<]+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the source variable again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'Twitter for iPhone'</li>\n",
       "\t<li>'Twitter Web Client'</li>\n",
       "\t<li>'Twitter for iPhone'</li>\n",
       "\t<li>'Twitter for Android'</li>\n",
       "\t<li>'Twitter for Android'</li>\n",
       "\t<li>'Twitter for Android'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'Twitter for iPhone'\n",
       "\\item 'Twitter Web Client'\n",
       "\\item 'Twitter for iPhone'\n",
       "\\item 'Twitter for Android'\n",
       "\\item 'Twitter for Android'\n",
       "\\item 'Twitter for Android'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'Twitter for iPhone'\n",
       "2. 'Twitter Web Client'\n",
       "3. 'Twitter for iPhone'\n",
       "4. 'Twitter for Android'\n",
       "5. 'Twitter for Android'\n",
       "6. 'Twitter for Android'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"Twitter for iPhone\"  \"Twitter Web Client\"  \"Twitter for iPhone\" \n",
       "[4] \"Twitter for Android\" \"Twitter for Android\" \"Twitter for Android\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(df$source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've cleaned up these variables, let's run poisson regression to analyze the source as a predictor of the count variable representing the number of hashtags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = hashtag_count ~ source, family = poisson, data = df)\n",
       "\n",
       "Deviance Residuals: \n",
       "     Min        1Q    Median        3Q       Max  \n",
       "-0.97714  -0.71506  -0.49655   0.01192   2.90773  \n",
       "\n",
       "Coefficients:\n",
       "                                         Estimate Std. Error z value Pr(>|z|)\n",
       "(Intercept)                             6.931e-01  7.071e-01   0.980    0.327\n",
       "sourceBuffer                            9.163e-01  8.367e-01   1.095    0.273\n",
       "sourceCRANberries Feed                 -6.931e-01  1.225e+00  -0.566    0.571\n",
       "sourceCalcaware                        -6.931e-01  1.225e+00  -0.566    0.571\n",
       "sourceEchofon                          -6.931e-01  1.000e+00  -0.693    0.488\n",
       "sourceFlamingo for Android              4.055e-01  9.129e-01   0.444    0.657\n",
       "sourceMachine learning Bot 6           -6.931e-01  1.225e+00  -0.566    0.571\n",
       "sourceR Weekly Live                    -1.386e-15  1.000e+00   0.000    1.000\n",
       "sourceRoundTeam                        -8.389e-16  1.000e+00   0.000    1.000\n",
       "sourceRstats1234                       -1.591e-01  7.311e-01  -0.218    0.828\n",
       "sourceTweetDeck                        -6.931e-01  1.225e+00  -0.566    0.571\n",
       "sourceTweetbot for i<U+039F>S          -6.931e-01  1.225e+00  -0.566    0.571\n",
       "sourceTweets that are just super duper -2.877e-01  9.129e-01  -0.315    0.753\n",
       "sourceTwitter Lite                     -1.823e-01  7.746e-01  -0.235    0.814\n",
       "sourceTwitter Web Client               -5.407e-02  7.265e-01  -0.074    0.941\n",
       "sourceTwitter for Android               1.476e-01  7.208e-01   0.205    0.838\n",
       "sourceTwitter for Mac                  -6.931e-01  1.000e+00  -0.693    0.488\n",
       "sourceTwitter for iPad                 -6.931e-01  1.225e+00  -0.566    0.571\n",
       "sourceTwitter for iPhone               -3.390e-02  7.311e-01  -0.046    0.963\n",
       "sourcemathhiasoso                      -6.931e-01  1.225e+00  -0.566    0.571\n",
       "sourceretweetsapplication              -5.486e-16  1.000e+00   0.000    1.000\n",
       "sourcetotem-socket                     -6.931e-01  1.225e+00  -0.566    0.571\n",
       "sourcettools it knowingness             9.163e-01  8.367e-01   1.095    0.273\n",
       "\n",
       "(Dispersion parameter for poisson family taken to be 1)\n",
       "\n",
       "    Null deviance: 97.578  on 99  degrees of freedom\n",
       "Residual deviance: 81.264  on 77  degrees of freedom\n",
       "AIC: 365.4\n",
       "\n",
       "Number of Fisher Scoring iterations: 5\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## poisson regression model\n",
    "m1 <- glm(hashtag_count ~ source, df, family = poisson)\n",
    "\n",
    "## summarize results\n",
    "summary(m1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code chunk, provide a brief write up of the results from the poisson model. This shouldn't require additional analyses or plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Microsoft PowerApps and Flow displays the highest z-score, indicating it's the most likely source for generating the desired hashtag. Other sources with a z-score above 2 are also more likely to include the hashtag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- your answer goes here -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
